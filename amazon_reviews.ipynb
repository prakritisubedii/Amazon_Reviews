{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a27ab7-e25b-43b0-a2dd-2a65d5ddd62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviewText', 'overall'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prakritisubedi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/prakritisubedi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/prakritisubedi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/prakritisubedi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path= 'Electronics_5.json'\n",
    "data= pd.read_json(file_path, lines=True)\n",
    "\n",
    "missing_values=data.isnull().sum()\n",
    "reviews= data[['reviewText', 'overall']]\n",
    "print(reviews.columns)\n",
    "\n",
    "reviews= reviews.dropna(subset=['reviewText', 'overall'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix=tfidf.fit_transform(reviews['reviewText'])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text=text.lower()\n",
    "\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=[word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "reviews['cleaned_reviewText']=reviews['reviewText'].apply(preprocess_text)\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia= SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "reviews['sentiment_score']= reviews['cleaned_reviewText'].apply(analyze_sentiment)\n",
    "\n",
    "def get_filtered_reviews(product_name):\n",
    "    filtered_reviews= reviews[reviews['summary'].str.contains(product_name, case=False, na=False)]\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "def get_recommendations(index, cosine_sim=cosine_sim):\n",
    "    sim_scores=list(enumerate(cosine_sim[index]))\n",
    "    sim_scores= sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores=sim_scores[1:6]\n",
    "    review_indices=[i[0] for i in sim_scores] \n",
    "    \n",
    "    recommended_reviews= reviews.iloc[review_indices].sort_values(by='sentiment_score', ascending=False)\n",
    "    \n",
    "    return recommended_reviews[['reviewText','sentiment_score']]\n",
    "\n",
    "reviews['asin'] = data['asin']\n",
    "\n",
    "def recommend_products(product_type):\n",
    "    filtered_reviews = reviews[reviews['reviewText'].str.contains(product_type, case=False, na=False)]\n",
    "    \n",
    "    if filtered_reviews.empty:\n",
    "        print(f\"No reviews found for the product type: {product_type}.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    product_sentiment = filtered_reviews.groupby('asin').agg({\n",
    "        'sentiment_score': 'mean',\n",
    "        'overall': 'mean',\n",
    "        'reviewText': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    top_products = product_sentiment.sort_values(by=['overall', 'sentiment_score'], ascending=False).head(5)\n",
    "    \n",
    "    return top_products[['asin', 'reviewText', 'overall', 'sentiment_score']]\n",
    "\n",
    "def display_review_simple(review_text):\n",
    "    short_review = review_text[:50] + '...' if len(review_text) > 50 else review_text\n",
    "    print(short_review)\n",
    "    \n",
    "    read_more = input(\"Do you want to read the full review? (yes/no): \").lower()\n",
    "    \n",
    "    if read_more == 'yes':\n",
    "        print(\"Full Review:\\n\", review_text)\n",
    "    else:\n",
    "        print(\"Skipped full review.\\n\")\n",
    "\n",
    "\n",
    "product_type = input(\"Enter the type of electronic device you're looking for (e.g., 'laptop', 'hairdryer'): \")\n",
    "top_recommendations = recommend_products(product_type)\n",
    "\n",
    "if not top_recommendations.empty:\n",
    "    for index, row in top_recommendations.iterrows():\n",
    "        print(f\"Product ASIN: {row['asin']}, Rating: {row['overall']}, Sentimnent score: {row['sentiment_score']}\")\n",
    "        display_review_simple(row['reviewText'])\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"No recommendations to display.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b561df-9969-4170-b2da-b73b822cd839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe69ed-14b0-45e2-9d30-a2e1e48791a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
